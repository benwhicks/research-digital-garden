---
{"dg-publish":true,"permalink":"/pairwise-comparison-rule/"}
---

#mathematical-modelling/game-theory 
A method in [[game-theory\|game-theory]] for calculating [[evolutionary-game-dynamics\|evolutionary-game-dynamics]]. 

> [!quote] From [EGTtools documentation](https://egttools.readthedocs.io/en/latest/tutorials/analytical_methods.html)
> The replicator dynamics assumes that populations have infinite size. This is convenient from a technical point of view, as it allows using relatively simple differential equations to model complex evolutionary processes. However, in many occasions, when modelling realistic problems, we cannot neglect the stochastic effects that come along when individuals interact in finite populations ^[Arne Traulsen, Martin A Nowak, and Jorge M Pacheco. Stochastic dynamics of invasion and fixation. Physical Review E, 74(1):011909, 2006.].
> 
> We now consider a finite population of $Z$ individuals, who interact in groups of size $N \in [2,Z]$, in which they engage in strategic interactions (or games). Each individual can adopt one of the $n_s$ strategies. The success (or fitness) of an individual can be computed as the expected payoff of the game in a given state $\overrightarrow{x}$.
> 
> We adopt a stochastic birth-death process combined with the pairwise comparison rule ^[Jorge M Pacheco, Francisco C Santos, Max O Souza, and Brian Skyrms. Evolutionary dynamics of collective action in N-person stag hunt dilemmas. Proceedings of the Royal Society B: Biological Sciences, 276(1655):315–321, 2009. doi:10.1098/rspb.2008.1126.] ^[Arne Traulsen, Martin A Nowak, and Jorge M Pacheco. Stochastic dynamics of invasion and fixation. Physical Review E, 74(1):011909, 2006.] ^[Drew Fudenberg and Lorens A. Imhof. Imitation processes with small mutations. Journal of Economic Theory, 131(1):251–262, 2006. doi:10.1016/j.jet.2005.04.006.] to describe the social learning dynamics of each of the strategies in a finite population. At each time-step, a randomly chosen individual $j$ adopting strategy $\overrightarrow{e}_{j}$ has the opportunity to revise her strategy by imitating (or not) the strategy of a randomly selected member of the population $i$. The imitation will occur with a probability $p$ which increases with the fitness difference between $j$ and $i$. Here we adopt the Fermi function (see Equation below), which originates from statistical physics and provides a well defined mapping between $\mathbb{R}^{+}\rightarrow [0,1]$. Please also note that since the population is finite, instead of assuming the frequencies of each strategy in the population ($x_i$) we use the absolute value $k_i$ so that $x_i \equiv [k_{i}/Z]$."
> 
> $$p \equiv [1+e^{\beta(f_i(k_i)-f_j(k_j))}]^{-1}$$
> 
> In equation above, $f_i(k_i)$ is the fitness of individual $i$ and $\beta$, also known as inverse temperature, conrols the intensity of selection and the accuracy of the imitation process. For $\beta \rightarrow 0$ individual fitness is but a small perturbation to random drift; for $\beta \rightarrow \infty$ imitation becomes increasingly deterministic. Also, $k_i$ represents again the total number of individuals adopting strategy $i$. In addition, we consider that, with a mutation (or exploration) probability $\mu$ individuals adopt a randomly chosen strategy, freely exploring the strategy space. Overall this adaptive process defines a large-scale Markov chain in which the transition probabilities between states are defined in function of the fitness of the strategies in the population and their frequency. The complete characterization of this process becomes unfeasible as the number of possible population configurations scales with the population size and the number of strategies following 