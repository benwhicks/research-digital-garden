---
{"dg-publish":true,"permalink":"/sources/lundie-givenness-human-learning2017/","title":"The Givenness of the Human Learning Experience and Its Incompatibility with Information Analytics","tags":["ðŸ“–"]}
---


Lundie, D. (2017). The Givenness of the Human Learning Experience and Its Incompatibility with Information Analytics. _Educational Philosophy and Theory_, _49_(4), 391â€“404. [https://doi.org/10.1080/00131857.2015.1052357](https://doi.org/10.1080/00131857.2015.1052357)
[online](http://zotero.org/users/5872672/items/4HQBTPJP) [local](zotero://select/library/items/4HQBTPJP) [pdf](file:///Users/14055622/Zotero/storage/VVP8USAC/Lundie%20-%202017%20-%20The%20Givenness%20of%20the%20Human%20Learning%20Experience%20and.pdf)

Highlights the fundamental tension between what we experience of as 'learning' and how we analyse it using information artefacts. 

> [!quote] 
> the article identifies a fundamental incompatibility between the subjective experience of learning and the information-theoretic account of knowledge

The proxy data we are analysing is not learning. They might have predictive capability but this disconnect and it's reductive view poses a threat to contemporary education. 

> [!quote] 
> Metadata is information according to the information-theoretic definition, it is meaningful when used to calculate the probability of a given state of affairs â€“ how likely is it, given the number of words John reads in 60 seconds, that he will be capable of success in English Literature at AS Level. It is not information about the learner as subject â€“ it is unconcerned with consciously willed dispositions or the intentions of the learner. Individuals generate metadata without having any conscious sense of doing so â€“ keystroke patterns, eye tracker movements, even brain states â€“ this data can be aggregated to produce a complex and granular picture with remarkable predictive capacity, yet it entirely ignores conscious human subjectivity. As I hope to have demonstrated, the definitions of knowledge, learning and intelligence derived from the philosophy of computing, as commonly used in definitions of â€˜machine learningâ€™ or â€˜artificial intelligenceâ€™, are at best metaphors for simulations of human-like processes. As metaphors, such terms are highly satisfactory in the design of systems. Design aimed at optimizing human learning, however, requires first a recognition that these definitions are insufficient, and secondly an engagement with philosophical pedagogy and the human sciences. Failure to do so can result in a reductive call-response measure of optimal learning as the merest transmission of information. This reductive informationalism represents a clear and present threat to contemporary education.


### Connections

supports:: 
refutes:: 

### Notes