---
{"dg-publish":true,"permalink":"/genai-in-education/"}
---


# Scoping

## GenAI in Ed: Feedback



## GenAI in Ed: Relationships

## GenAI in Ed: Assessment

## GenAI in Ed: Knowledge

## GenAI in Ed: Learning

Is faster actually better? A lot of the lauded benefits of [[generative-artificial-intelligence\|generative-artificial-intelligence]] are around making things faster, more efficient, but is this actually of benefit to learning? The brain, and THINKING, is a limiting factor here. Sometimes learning is slow. 
h
Alternatively, what would a heavily augmented teaching practice look like, based on GenAI, where the student *never* sees the AI? For instance, supported in planning and admin, but not in the classroom. 

Does the technology assist in the cognitive process, or supplant it? A calculator offloads numeracy, where as an abacus supports it. What will Chatty-G be?

We may want to make sure that students can 'use these tools effectively' or have sound judgement, but what does this mean? What is the pre-requisite knowledge to be able to do this? It is at least probability, and likely conditional probability, but also nuance of language, understanding uncertainty, data sets, etc. 

# Pitfalls

- Anthropic says this is safe, robust and transparent, but [[what-does-safe-robust-and-transparent-AI-mean\|what-does-safe-robust-and-transparent-AI-mean]] in this context?

# Ways forward

# References

## Talks

### [What's wrong with LLMs and what should we be using instead?](https://www.youtube.com/watch?v=cEyHsMzbZBs&list=WL&index=6&ab_channel=valgrAI)

Great talk, pushing the idea of Knowledge graphs. Key line is that these models are not [[knowledge-bases\|knowledge-bases]] but in fact [[statistical-models\|statistical-models]] of knowledge bases, but we treat them as though they do have knowledge, and not a probabilistic understanding of knowledge. A further point here is that they treat all [[uncertainty\|uncertainty]] as [[aleotoric uncertainty\|aleotoric uncertainty]] and not [[epistemic uncertainty\|epistemic uncertainty]], that is everything is stochastic. A machine that acknowledges [[epistemic uncertainty\|epistemic uncertainty]] should be able to say "I don't know". 

### [Exploring GenAI and the law](https://www.youtube.com/watch?v=5GmVqymaIcw&t=2040&ab_channel=SiliconFlatirons)

Point (above) on what does safe